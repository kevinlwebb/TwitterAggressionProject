{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Project Definition](#Project-Definition)\n",
    "- [Analysis](#Analysis)\n",
    "- [Conclusion](#Conclusion)\n",
    "- [Future Work](#Future-Work)\n",
    "- [Guides](#Guides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Definition\n",
    "\n",
    "Utilizing and analyzing a dataset of classified Tweets from [Dataturks through Kaggle](https://www.kaggle.com/dataturks/dataset-for-detection-of-cybertrolls) to build a model that classifies Tweets between good or bad and display results in a Flask web application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional analysis has been done on Kaggle:\n",
    "<br>https://www.kaggle.com/kevinlwebb/cybertrolls-exploration-and-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwebb/Desktop/env/ds/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/Users/kevinwebb/Desktop/env/ds/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence, defaultdict\n",
      "/Users/kevinwebb/Desktop/env/ds/lib/python3.7/site-packages/nltk/lm/vocabulary.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Counter, Iterable\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kevinwebb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/kevinwebb/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kevinwebb/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from joblib import dump, load\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "engine = create_engine('sqlite:///data/TweetSentiment.db')\n",
    "df = pd.read_sql_table('tweets', engine)\n",
    "\n",
    "# load model\n",
    "model = load(\"models/classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       cleaned_tweet label\n",
       "0                             Get fucking real dude.     1\n",
       "1   She is as dirty as they come  and that crook ...     1\n",
       "2   why did you fuck it up. I could do it all day...     1\n",
       "3   Dude they dont finish enclosing the fucking s...     1\n",
       "4   WTF are you talking about Men? No men thats n...     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cleaned_tweet\n",
       "label               \n",
       "0              12179\n",
       "1               7822"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of bad tweets: 39.10804459777012\n",
      "Percent of good tweets: 60.89195540222989\n"
     ]
    }
   ],
   "source": [
    "bad_per = (len(df[df.label == '1']) / len(df)) * 100\n",
    "print(\"Percent of bad tweets: {}\".format(bad_per))\n",
    "\n",
    "good_per = (len(df[df.label == '0']) / len(df)) * 100\n",
    "print(\"Percent of good tweets: {}\".format(good_per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")\n",
    "text = df.cleaned_tweet.str.cat(sep=' ')\n",
    "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "str_list = text.split(\" \")\n",
    "s = pd.Series(str_list)\n",
    "s = s[s != \"\"]\n",
    "s = s[~s.isin(sw)]\n",
    "\n",
    "top_10 = s.value_counts()[:10]\n",
    "word_counts = s.value_counts()[:10].tolist()\n",
    "word_names = s.value_counts()[:10].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 General Words\n",
      "hate       2833\n",
      "damn       2485\n",
      "ass        1820\n",
      "sucks      1537\n",
      "fuck       1494\n",
      "lol        1440\n",
      "like       1440\n",
      "get        1046\n",
      "fucking     997\n",
      "u           984\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 General Words\")\n",
    "print(top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[df.label == '1'].cleaned_tweet.str.cat(sep=' ')\n",
    "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "str_list = text.split(\" \")\n",
    "s = pd.Series(str_list)\n",
    "s = s[s != \"\"]\n",
    "s = s[~s.isin(sw)]\n",
    "\n",
    "bad_top_10 = s.value_counts()[:10]\n",
    "bad_word_counts = s.value_counts()[:10].tolist()\n",
    "bad_word_names = s.value_counts()[:10].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Bad Words\n",
      "hate       1326\n",
      "damn       1110\n",
      "fuck       1070\n",
      "ass        1070\n",
      "sucks       724\n",
      "fucking     634\n",
      "lol         596\n",
      "u           512\n",
      "bitch       502\n",
      "like        500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 Bad Words\")\n",
    "print(bad_top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[df.label == '0'].cleaned_tweet.str.cat(sep=' ')\n",
    "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "str_list = text.split(\" \")\n",
    "s = pd.Series(str_list)\n",
    "s = s[s != \"\"]\n",
    "s = s[~s.isin(sw)]\n",
    "\n",
    "good_top_10 = s.value_counts()[:10]\n",
    "good_word_counts = s.value_counts()[:10].tolist()\n",
    "good_word_names = s.value_counts()[:10].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Good Words\n",
      "hate     1507\n",
      "damn     1375\n",
      "like      940\n",
      "lol       844\n",
      "sucks     813\n",
      "ass       750\n",
      "would     694\n",
      "get       599\n",
      "one       528\n",
      "know      515\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 Good Words\")\n",
    "print(good_top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Tweet 'I hate you' is a good tweet\n"
     ]
    }
   ],
   "source": [
    "query = \"I hate you\"\n",
    "\n",
    "if model.predict([query])[0] == '0':\n",
    "    print(\"The Tweet '{}' is a good tweet\".format(query))\n",
    "else:\n",
    "    print(\"The Tweet '{}' is a bad tweet\".format(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The divide of data between good and bad is great, but after seeing that 'hate' and other bad words are shared between classified bad and good, the data is still skewed. The model was tested above with a sentence with clear bad sentiment, but because of the skewed data (and other factors), the model predicted that the sentence has 'good' sentiment.\n",
    "\n",
    "Below, you'll find different methods and solutions that may help in correctly classifying Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "\n",
    "- Implement analysis on live Tweets\n",
    "- Switch from classification to regression\n",
    "- Switch and / or add new dataset\n",
    "  - [sentiment140 dataset](https://www.kaggle.com/kazanova/sentiment140)\n",
    "- Use more libraries and tools\n",
    "  - textblob\n",
    "- Utilize Hashtags, Emoticons, and Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tweepy import Stream, OAuthHandler, API\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter credentials for the app\n",
    "consumer_key = os.environ['twitter_consumer_key']\n",
    "consumer_secret = os.environ['twitter_consumer_secret']\n",
    "access_key= os.environ['twitter_access_key']\n",
    "access_secret = os.environ['twitter_access_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass twitter credentials to tweepy\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HappyEmoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = api.user_timeline(user_id=\"realDonaldTrump\", count=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://t.co/61KbAnpncb\n",
      "Hey Google! Where's my shirt? ğŸ˜\n",
      "#GCP #GoogleCloud @GCPcloud https://t.co/y8s4UhkT5m \n",
      "\n",
      "#ATTLIVE17 amazing things happen here https://t.co/21TovQK4Ub \n",
      "\n",
      "#ATTLIVE17 caught in the act https://t.co/VEcGwbbOoC \n",
      "\n",
      "#ATTLIVE17 morning views https://t.co/dcf6Q5N1wX \n",
      "\n",
      "@DTgolfstar @CauseWereGuys better goalie than I'll ever be. It should be Central's goalkeeper coach ğŸ‘€ \n",
      "\n",
      "RT @bayer04fussball: #Chicharito kommt von @ManUtd und unterschreibt bei der #Werkself bis 2018 || @CH14_ joins #Bayer04 until 2018! http:/â€¦ \n",
      "\n",
      "@destiny_belle getting there at 11 vs getting a decent parking spot. Your choice ğŸ˜† \n",
      "\n",
      "@destiny_belle get there earlier \n",
      "\n",
      "RT @Lambdas1975: Congratulations to Delta Zeta Chapter (University of West Georgia) for earning the highest fraternity chapter GPA... http:â€¦ \n",
      "\n",
      "@Andy_Hartsfield you forgot #kevinislame gosh! \n",
      "\n",
      "@VivaDat_Stud how you should feel http://t.co/G5Z5GMpq4z \n",
      "\n",
      "@destiny_belle so... is this confirmation to do it? Or nah? \n",
      "\n",
      "@destiny_belle demand a year's worth of McNuggets!! \n",
      "\n",
      "RT @Lambdas1975: Brothers from the University of West Georgia (Delta Zeta Chapter) improving the community on Stripling Chapel... http://t.â€¦ \n",
      "\n",
      "End of the Ninja Skillz Saga https://t.co/Ae6u3okjIA \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for what in timeline:\n",
    "    print(what.text, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = api.search(q=\"Trump\", tweet_mode = 'extended', lang=\"en\", rpp=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @NewsCorpse: Trump says he was \"distracted\" by his impeachment from addressing the coronavirus. If that's true, it means he cared more aâ€¦ \n",
      "---------------------------\n",
      "\n",
      "RT @JenAshleyWright: Thereâ€™s always a Trump tweet that aged poorly. https://t.co/RwkCkYQNTO \n",
      "---------------------------\n",
      "\n",
      "@AdyBarkan @JoeBiden Nothing, Iâ€™m only voting for him because heâ€™s not Trump. Heâ€™s not progressive so whatever. \n",
      "---------------------------\n",
      "\n",
      "RT @AngelaBelcamino: @realDonaldTrump @nytimes To clarify to you all why DJT is throwing a hissing fit baby tantrum... It's because the Walâ€¦ \n",
      "---------------------------\n",
      "\n",
      "RT @Barnes_Law: How Clinton Allies Hijacked Policy Response to Pandemic to Try and Sink Trump's Re-election https://t.co/b5zTgKTZVn \n",
      "---------------------------\n",
      "\n",
      "RT @HowardA_Esq: Today, acting president Cuomo, his voice breaking, spoke about the horrifying number of New Yorkers, 799, that died in theâ€¦ \n",
      "---------------------------\n",
      "\n",
      "RT @mitchellvii: President Trump needs smart people like Dr. SHIVA \n",
      "@va_shiva on his pandemic panel next time to balance the whacky leftistâ€¦ \n",
      "---------------------------\n",
      "\n",
      "RT @TomthunkitsMind: If Trump delays the election, both him &amp; Pence will be removed by forfeit. Speaker Pelosi will become POTUS. I am suggâ€¦ \n",
      "---------------------------\n",
      "\n",
      "RT @funder: BREAKING: CNN did not air Trumpâ€™s press conference live today \n",
      "---------------------------\n",
      "\n",
      "RT @JuddLegum: This is a stunning story. WTF is going on?\n",
      "\n",
      "\"Although President Trump has directed states and hospitals to secure what supplâ€¦ \n",
      "---------------------------\n",
      "\n",
      "RT @JohnJHarwood: new @CNN poll of registered voters: \n",
      "\n",
      "Biden 53%\n",
      "Trump 42% \n",
      "---------------------------\n",
      "\n",
      "@elprimodany What do you mean it fell too?? It was during Obamaâ€™s admin that unemployment dropped after the eco crash of 09. Trump came in when unemployment had recovered. Thereâ€™s people who need to be on safety nets, thatâ€™s just how it is because hereâ€™s another problem: the fed min (1) \n",
      "---------------------------\n",
      "\n",
      "RT @HKrassenstein: BREAKING: Republican Ohio Governor Mike Dewine contradicts Trump and calls Ohioâ€™s mail-in ballot system safe and secure.â€¦ \n",
      "---------------------------\n",
      "\n",
      "RT @uppittynegress: Dems be like: but omg the scotus pick if trump wins!1! \n",
      "\n",
      "Also Dems: silent af when this happened\n",
      "\n",
      "https://t.co/hKFFS9zyâ€¦ \n",
      "---------------------------\n",
      "\n",
      "@gtconway3d i donâ€™t think it is limited to the trump campaign.  the same can be said of the entire GOP. \n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in search:\n",
    "    print(tweet.full_text, \"\\n---------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = api.search(q=\"Alexandria Ocasio-Cortez\", lang=\"en\", tweet_mode = 'extended', include_rts=False, rpp=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "RT @DianeLong22: 'ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ AOC in the Middle of a Pandemic?? ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ \n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Guest Judgeâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @TribulationThe: AOC is definitely ONE EVIL and CRAZY WOMAN!!!ğŸ˜¡ğŸ˜¡ğŸ˜¡\n",
      "\n",
      "'I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Gueâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @DianeLong22: 'ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ AOC in the Middle of a Pandemic?? ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ \n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Guest Judgeâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @DianeLong22: 'ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ AOC in the Middle of a Pandemic?? ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ \n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Guest Judgeâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "Tonight at 11PM EST / 8PM PST @Diddy will host a virtual town hall joined by Angela Rye, Congressperson Alexandria Ocasio-Cortez, Killer Mike, Charles Blow, Van Jones and more https://t.co/KnU9qKDpI4\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @DianeLong22: 'ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ AOC in the Middle of a Pandemic?? ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ \n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Guest Judgeâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @TribulationThe: AOC is definitely ONE EVIL and CRAZY WOMAN!!!ğŸ˜¡ğŸ˜¡ğŸ˜¡\n",
      "\n",
      "'I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Gueâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @DianeLong22: 'ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ AOC in the Middle of a Pandemic?? ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ \n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Guest Judgeâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @TribulationThe: AOC is definitely ONE EVIL and CRAZY WOMAN!!!ğŸ˜¡ğŸ˜¡ğŸ˜¡\n",
      "\n",
      "'I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Gueâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @DianeLong22: 'ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ AOC in the Middle of a Pandemic?? ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ \n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Guest Judgeâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @DianeLong22: 'ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ AOC in the Middle of a Pandemic?? ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ \n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Guest Judgeâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @DianeLong22: 'ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ AOC in the Middle of a Pandemic?? ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ \n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Guest Judgeâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @DianeLong22: 'ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ AOC in the Middle of a Pandemic?? ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ \n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Guest Judgeâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @DianeLong22: 'ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ AOC in the Middle of a Pandemic?? ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ ğŸ¦ \n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Be Guest Judgeâ€¦\n",
      "\n",
      "---------\n",
      "\n",
      "False\n",
      "RT @YesToTheUS: Dang NY, you sure know how to pick â€˜em ğŸ™„\n",
      "\n",
      "ğŸ‘‡ğŸ¼ğŸ‘‡ğŸ¼ğŸ‘‡ğŸ¼ğŸ‘‡ğŸ¼ğŸ‘‡ğŸ¼ğŸ‘‡ğŸ¼ğŸ‘‡ğŸ¼ğŸ‘‡ğŸ¼\n",
      "\n",
      "I Pledge Allegiance To The Drag': Alexandria Ocasio-Cortez to Bâ€¦\n",
      "\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in search:\n",
    "    print(tweet.truncated)\n",
    "    print(tweet.full_text)\n",
    "    print(\"\\n---------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guides\n",
    "\n",
    "https://towardsdatascience.com/extracting-twitter-data-pre-processing-and-sentiment-analysis-using-python-3-0-7192bd8b47cf\n",
    "\n",
    "https://towardsdatascience.com/tweepy-for-beginners-24baf21f2c25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
